{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d125b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì • (ì‹¤ì œ í‚¤ë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-openai-api-key-here'\n",
    "os.environ['SUPABASE_URL'] = 'your-supabase-url-here'\n",
    "os.environ['SUPABASE_KEY'] = 'your-supabase-key-here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "from openai import OpenAI\n",
    "from supabase import create_client, Client\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "CANDIDATE_POOL = 30\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "CE_MODEL = \"BAAI/bge-reranker-v2-m3\"\n",
    "KW_BONUS_ALPHA = 1.2\n",
    "\n",
    "KEYWORD_TRANSLATION = {\n",
    "    \"antiaging\": [\"ì•ˆí‹°ì—ì´ì§•\", \"ì•ˆí‹°\", \"ì£¼ë¦„\", \"ì£¼ë¦„ê°œì„ \", \"ì£¼ë¦„ì¼€ì–´\", \"íƒ„ë ¥\", \"íƒ„ë ¥ì¼€ì–´\", \"íƒ„ë ¥ê°œì„ \", \"ì–´ë ¤ë³´ì´ëŠ”\", \"í•­ì‚°í™”\", \"ë¦¬í”„íŒ…\", \"ë…¸í™”\", \"ì•ˆí‹°ì—ì´ì§€\", \"ê°œì„ íš¨ê³¼\"],\n",
    "    \"anti_aging\": [\"ì•ˆí‹°ì—ì´ì§•\", \"ì•ˆí‹°\", \"ì£¼ë¦„\", \"ì£¼ë¦„ê°œì„ \", \"ì£¼ë¦„ì¼€ì–´\", \"íƒ„ë ¥\", \"íƒ„ë ¥ì¼€ì–´\", \"íƒ„ë ¥ê°œì„ \", \"ì–´ë ¤ë³´ì´ëŠ”\", \"í•­ì‚°í™”\", \"ë¦¬í”„íŒ…\", \"ë…¸í™”\", \"ê°œì„ íš¨ê³¼\"],\n",
    "    \"firming\": [\"íƒ„ë ¥\", \"íƒ„ë ¥ì¼€ì–´\", \"íƒ„ë ¥ê°œì„ \", \"ë¦¬í”„íŒ…\", \"í¼ë°\", \"íƒ„íƒ„\", \"elasticity\", \"firmness\", \"ê¸´ì¥\", \"í”¼ë¶€íƒ„ë ¥\"],\n",
    "    \"whitening\": [\"í™”ì´íŠ¸ë‹\", \"ë¯¸ë°±\", \"ë¸Œë¼ì´íŠ¸ë‹\", \"í†¤ì—…\", \"brightening\", \"ë¸Œë¼ì´íŠ¸\", \"í™”ì‚¬\", \"í”¼ë¶€í†¤\", \"í†¤ê°œì„ \"],\n",
    "    \"brightening\": [\"ë¸Œë¼ì´íŠ¸ë‹\", \"í™”ì´íŠ¸ë‹\", \"ë¯¸ë°±\", \"í†¤ì—…\", \"í™”ì‚¬\", \"í”¼ë¶€í†¤\", \"ë°ì€\"],\n",
    "    \"nutrition\": [\"ì˜ì–‘\", \"nutrition\", \"ì˜ì–‘ê°\", \"ì˜ì–‘ê³µê¸‰\", \"ì˜ì–‘í¬ë¦¼\", \"nourishing\"],\n",
    "    \"moisturizing\": [\"ë³´ìŠµ\", \"ë³´ìŠµê°\", \"ë³´ìŠµë ¥\", \"ìˆ˜ë¶„\", \"ìˆ˜ë¶„ê°\", \"ìˆ˜ë¶„ê³µê¸‰\", \"ì´‰ì´‰\", \"ì´‰ì´‰í•œ\", \"hydrating\", \"í•˜ì´ë“œë ˆì´íŒ…\", \"moisturize\"],\n",
    "    \"hydrating\": [\"ìˆ˜ë¶„\", \"ìˆ˜ë¶„ê°\", \"ìˆ˜ë¶„ê³µê¸‰\", \"ë³´ìŠµ\", \"ë³´ìŠµê°\", \"ì´‰ì´‰\", \"ì´‰ì´‰í•œ\"],\n",
    "    \"nourishing\": [\"ì˜ì–‘\", \"ì˜ì–‘ê°\", \"ì˜ì–‘ê³µê¸‰\", \"ì˜ì–‘í¬ë¦¼\"],\n",
    "    \"exfoliating\": [\"ê°ì§ˆ\", \"ê°ì§ˆì œê±°\", \"ê°ì§ˆì¼€ì–´\", \"ê°ì§ˆê´€ë¦¬\", \"peeling\", \"í•„ë§\"],\n",
    "    \"peeling\": [\"í•„ë§\", \"ê°ì§ˆì œê±°\", \"ê°ì§ˆì¼€ì–´\", \"ê°ì§ˆ\"],\n",
    "    \"soothing\": [\"ì§„ì •\", \"ìˆ˜ë”©\", \"í¸ì•ˆ\", \"í¸ì•ˆí•œ\", \"calm\", \"calming\", \"ì§„ì •íš¨ê³¼\"],\n",
    "    \"calming\": [\"ì§„ì •\", \"ìˆ˜ë”©\", \"í¸ì•ˆ\", \"í¸ì•ˆí•œ\", \"calm\"],\n",
    "    \"sensitive\": [\"ë¯¼ê°\", \"ë¯¼ê°ì„±\", \"ìˆœí•œ\", \"ìê·¹ì—†ëŠ”\", \"gentle\", \"ì„¼ì‹œí‹°ë¸Œ\", \"ë¯¼ê°ì„±í”¼ë¶€\", \"ë¯¼ê°í”¼ë¶€\"],\n",
    "    \"acne\": [\"ì—¬ë“œë¦„\", \"íŠ¸ëŸ¬ë¸”\", \"ì•„í¬ë„¤\", \"í”¼ì§€\", \"ëª¨ê³µ\", \"trouble\"],\n",
    "    \"pore\": [\"ëª¨ê³µ\", \"pore\", \"í”¼ì§€\", \"ë¸”ë™í—¤ë“œ\", \"ëª¨ê³µì¼€ì–´\"],\n",
    "    \"sebum\": [\"í”¼ì§€\", \"ìœ ë¶„\", \"sebum\", \"ì˜¤ì¼\", \"ìœ ë¶„ì¡°ì ˆ\"],\n",
    "    \"dry\": [\"ê±´ì¡°\", \"ê±´ì„±\", \"ìˆ˜ë¶„ë¶€ì¡±\", \"ë‹¹ê¹€\"],\n",
    "    \"oily\": [\"ì§€ì„±\", \"ìœ ë¶„\", \"í”¼ì§€\", \"ë²ˆë“¤ê±°ë¦¼\"],\n",
    "    \"premium\": [\"í”„ë¦¬ë¯¸ì—„\", \"ê³ ê¸‰\", \"ëŸ­ì…”ë¦¬\", \"luxury\", \"í•˜ì´ì—”ë“œ\"],\n",
    "    \"luxury\": [\"ëŸ­ì…”ë¦¬\", \"í”„ë¦¬ë¯¸ì—„\", \"ê³ ê¸‰\", \"í•˜ì´ì—”ë“œ\"],\n",
    "    \"glow\": [\"ê¸€ë¡œìš°\", \"ê´‘ì±„\", \"ìœ¤ê¸°\", \"ë¹›\", \"ìƒê¸°\", \"radiance\", \"ë˜ë””ì–¸ìŠ¤\"],\n",
    "    \"radiance\": [\"ë˜ë””ì–¸ìŠ¤\", \"ê¸€ë¡œìš°\", \"ê´‘ì±„\", \"ìœ¤ê¸°\", \"ë¹›\", \"ìƒê¸°\"],\n",
    "    \"dermatologist_tested\": [\"í”¼ë¶€ê³¼\", \"í…ŒìŠ¤íŠ¸\", \"ì„ìƒ\", \"dermatologist\", \"í”¼ë¶€ê³¼í…ŒìŠ¤íŠ¸\", \"í…ŒìŠ¤íŠ¸ì™„ë£Œ\"],\n",
    "    \"dermatologisttested\": [\"í”¼ë¶€ê³¼\", \"í…ŒìŠ¤íŠ¸\", \"ì„ìƒ\", \"dermatologist\", \"í”¼ë¶€ê³¼í…ŒìŠ¤íŠ¸\"],\n",
    "    \"lightweight\": [\"ê°€ë²¼ìš´\", \"ì‚°ëœ»í•œ\", \"light\", \"ê°€ë³ê²Œ\"],\n",
    "    \"light\": [\"ê°€ë²¼ìš´\", \"ì‚°ëœ»í•œ\", \"light\"],\n",
    "    \"soft\": [\"ë¶€ë“œëŸ¬ìš´\", \"ì†Œí”„íŠ¸\", \"soft\", \"ì´‰ì´‰\"],\n",
    "    \"gentle\": [\"ìˆœí•œ\", \"ë¶€ë“œëŸ¬ìš´\", \"gentle\", \"ìê·¹ì—†ëŠ”\"],\n",
    "    \"rich\": [\"ë¦¬ì¹˜\", \"ë†ì¶•\", \"ì˜ì–‘\", \"ì§„í•œ\"],\n",
    "    \"creamy\": [\"í¬ë¦¬ë¯¸\", \"í¬ë¦¼\", \"ë¶€ë“œëŸ¬ìš´\"],\n",
    "    \"absorption\": [\"í¡ìˆ˜\", \"í¡ìˆ˜ë ¥\", \"ë¹ ë¥¸í¡ìˆ˜\"],\n",
    "    \"nonsticky\": [\"ëˆì ì„ì—†ëŠ”\", \"ì‚°ëœ»í•œ\", \"ê°€ë²¼ìš´\"],\n",
    "    \"nondrying\": [\"ê±´ì¡°í•˜ì§€ì•Šì€\", \"ì´‰ì´‰í•œ\", \"ë³´ìŠµ\"],\n",
    "    \"affordable\": [\"ê°€ì„±ë¹„\", \"ê°€ê²©ì €ë ´í•œ\", \"í•©ë¦¬ì \", \"ê°€ê²©ëŒ€ë¹„\", \"ì €ë ´\"],\n",
    "    \"valueformoney\": [\"ê°€ì„±ë¹„\", \"ê°€ê²©ëŒ€ë¹„\", \"ê°€ì„±ë¹„ì¢‹ì€\"],\n",
    "    \"value_for_money\": [\"ê°€ì„±ë¹„\", \"ê°€ê²©ëŒ€ë¹„\", \"í•©ë¦¬ì \"],\n",
    "}\n",
    "\n",
    "WEATHER_KEYWORDS = {\n",
    "    \"spring\": [\"ë´„\", \"ë¯¸ì„¸ë¨¼ì§€\", \"í™©ì‚¬\", \"ê½ƒê°€ë£¨\", \"ì•ŒëŸ¬ì§€\", \"ì•Œë ˆë¥´ê¸°\", \"ì§„ì •\", \"ë³´í˜¸\", \"ë³´í˜¸ë§‰\", \"ë°°ë¦¬ì–´\", \"í´ë Œì§•\", \"ì„¸ì•ˆ\", \"ë”¥í´ë Œì§•\", \"ë¯¼ê°\", \"ë¯¼ê°ì„±\", \"ìê·¹ì™„í™”\", \"ìˆœí•œ\", \"ì €ìê·¹\", \"í•­ì‚°í™”\", \"ë¹„íƒ€ë¯¼C\", \"ì§„ì •íš¨ê³¼\", \"í”¼ë¶€ì§„ì •\", \"í”¼ë¶€ë³´í˜¸\"],\n",
    "    \"summer\": [\"ì—¬ë¦„\", \"í­ì—¼\", \"ìì™¸ì„ \", \"ì¥ë§ˆ\", \"ìŠµë„\", \"UV\", \"SPF\", \"PA\", \"ì„ í¬ë¦¼\", \"ì¬\", \"ì„ ì¼€ì–´\", \"ì¿¨ë§\", \"ì‹œì›í•œ\", \"ì‚°ëœ»í•œ\", \"ê°€ë²¼ìš´\", \"ë•€\", \"í”¼ì§€\", \"ëª¨ê³µ\", \"ìœ ë¶„\", \"ì§€ì„±\", \"ìˆ˜ë¶„\", \"ì ¤\", \"ì—ì„¼ìŠ¤\", \"ìì™¸ì„ ì°¨ë‹¨\", \"ìœ ë¶„ì¡°ì ˆ\", \"ëª¨ê³µì¼€ì–´\", \"í”¼ì§€ì¡°ì ˆ\", \"ì²­ëŸ‰\", \"ì²­ëŸ‰ê°\", \"ê°€ë²¼ìš´ì œí˜•\", \"ì‚°ëœ»í•œë°œë¦¼ì„±\"],\n",
    "    \"fall\": [\"ê°€ì„\", \"í™˜ì ˆê¸°\", \"ì¼êµì°¨\", \"ê±´ì¡°\", \"ê±´ì¡°í•œ\", \"ë³´ìŠµ\", \"ìˆ˜ë¶„\", \"ì§„ì •\", \"ë°¸ëŸ°ìŠ¤\", \"ì¥ë²½\", \"ë°°ë¦¬ì–´\", \"íšŒë³µ\", \"ë¦¬í˜ì–´\", \"ì˜ì–‘\", \"ì¼€ì–´\", \"í”¼ë¶€ì¥ë²½\", \"ì„¸ë¼ë§ˆì´ë“œ\", \"íˆì•Œë£¨ë¡ ì‚°\", \"í¬ë¦¼\", \"ë³´ìŠµê°\", \"íƒ„ë ¥\", \"ì´‰ì´‰í•œ\", \"ë¶€ë“œëŸ¬ìš´\", \"ì˜ì–‘ê³µê¸‰\", \"ì¥ë²½ë¦¬í˜ì–´\", \"í”¼ë¶€ë°€ë„\", \"ë°€ë„\"],\n",
    "    \"winter\": [\"ê²¨ìš¸\", \"í•œíŒŒ\", \"ê±´ì¡°\", \"ê·¹ê±´ì¡°\", \"ë³´ìŠµ\", \"ê³ ë³´ìŠµ\", \"ìˆ˜ë¶„\", \"í¬ë¦¼\", \"ì˜¤ì¼\", \"ë°¤\", \"ë†ì¶•\", \"ë¦¬ì¹˜\", \"ì˜ì–‘\", \"ì˜ì–‘í¬ë¦¼\", \"ë¦¬í”„íŒ…\", \"íƒ„ë ¥\", \"ë°€ì°©\", \"í”¼ë¶€ì¥ë²½\", \"ì„¸ë¼ë§ˆì´ë“œ\", \"ì´‰ì´‰í•œë³´ìŠµê°\", \"ë¶€ë“œëŸ¬ìš´ë°œë¦¼ì„±\", \"ì¥ë²½ë¦¬í˜ì–´\", \"í”¼ë¶€ë°€ë„\", \"ë°€ë„\"]\n",
    "}\n",
    "\n",
    "WEATHER_PRIORITY_KEYWORDS = {\n",
    "    \"spring\": [\"ì§„ì •\", \"ë¯¼ê°\", \"ìˆœí•œ\", \"ì €ìê·¹\", \"ë³´í˜¸\", \"ë°°ë¦¬ì–´\", \"í”¼ë¶€ë³´í˜¸\", \"í´ë Œì§•\", \"ë”¥í´ë Œì§•\", \"ì„¸ì•ˆ\", \"ì•ŒëŸ¬ì§€\", \"ì•Œë ˆë¥´ê¸°\", \"ìê·¹ì™„í™”\", \"ì§„ì •íš¨ê³¼\", \"í”¼ë¶€ì§„ì •\"],\n",
    "    \"summer\": [\"ì‚°ëœ»\", \"ì‚°ëœ»í•œ\", \"ê°€ë²¼ìš´\", \"ëˆì ì„ì—†ëŠ”\", \"ë…¼ìŠ¤í‹°í‚¤\", \"ì¿¨ë§\", \"ì‹œì›í•œ\", \"SPF\", \"PA\", \"ìì™¸ì„ \", \"ìì™¸ì„ ì°¨ë‹¨\", \"ì„ í¬ë¦¼\", \"ì„ ì¼€ì–´\", \"UV\", \"í”¼ì§€\", \"í”¼ì§€ì¡°ì ˆ\", \"ëª¨ê³µ\", \"ëª¨ê³µì¼€ì–´\", \"ìœ ë¶„ì¡°ì ˆ\", \"ì§€ì„±\", \"ì ¤\", \"ì²­ëŸ‰\", \"ì²­ëŸ‰ê°\", \"ê°€ë²¼ìš´ì œí˜•\", \"ì‚°ëœ»í•œë°œë¦¼ì„±\"],\n",
    "    \"fall\": [\"ë³´ìŠµ\", \"ìˆ˜ë¶„\", \"ì´‰ì´‰\", \"ì´‰ì´‰í•œ\", \"ê±´ì¡°\", \"ì¥ë²½\", \"ë°°ë¦¬ì–´\", \"í”¼ë¶€ì¥ë²½\", \"ì¥ë²½ë¦¬í˜ì–´\", \"íšŒë³µ\", \"ë¦¬í˜ì–´\", \"ì§„ì •\", \"ë°¸ëŸ°ìŠ¤\", \"ì˜ì–‘\", \"ì˜ì–‘ê³µê¸‰\", \"ì„¸ë¼ë§ˆì´ë“œ\", \"íˆì•Œë£¨ë¡ ì‚°\"],\n",
    "    \"winter\": [\"ë³´ìŠµ\", \"ê³ ë³´ìŠµ\", \"ìˆ˜ë¶„\", \"ê·¹ê±´ì¡°\", \"ê±´ì¡°\", \"í¬ë¦¼\", \"ë¦¬ì¹˜\", \"ë†ì¶•\", \"ë°€ì°©\", \"ì˜¤ì¼\", \"ë°¤\", \"ì˜ì–‘\", \"ì˜ì–‘í¬ë¦¼\", \"ì˜ì–‘ê³µê¸‰\", \"ì´‰ì´‰í•œë³´ìŠµê°\", \"ë¶€ë“œëŸ¬ìš´ë°œë¦¼ì„±\", \"ì„¸ë¼ë§ˆì´ë“œ\", \"í”¼ë¶€ì¥ë²½\", \"ì¥ë²½ë¦¬í˜ì–´\"]\n",
    "}\n",
    "\n",
    "def normalize_list(v: Any) -> List[str]:\n",
    "    if v is None: return []\n",
    "    if isinstance(v, list): return [str(x).strip() for x in v if str(x).strip()]\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s.startswith(\"{\") and s.endswith(\"}\"): s = s[1:-1]\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            import json\n",
    "            try: return json.loads(s)\n",
    "            except: pass\n",
    "        return [x.strip().strip('\"') for x in s.split(\",\") if x.strip()]\n",
    "    return [str(v).strip()]\n",
    "\n",
    "def expand_keywords(keywords: List[str]) -> List[str]:\n",
    "    expanded = []\n",
    "    for kw in keywords:\n",
    "        expanded.append(kw)\n",
    "        normalized = kw.lower().replace(\"_\", \"\").replace(\"-\", \"\").replace(\" \", \"\")\n",
    "        if normalized in KEYWORD_TRANSLATION:\n",
    "            expanded.extend(KEYWORD_TRANSLATION[normalized])\n",
    "    return expanded\n",
    "\n",
    "def get_current_season() -> str:\n",
    "    month = datetime.now().month\n",
    "    if month in [3, 4, 5]: return \"spring\"\n",
    "    elif month in [6, 7, 8]: return \"summer\"\n",
    "    elif month in [9, 10, 11]: return \"fall\"\n",
    "    else: return \"winter\"\n",
    "\n",
    "def keyword_bonus(user_keywords, product_content, product_keywords, skin_concerns=None, weather_keywords=None, current_season=None):\n",
    "    kws = [k.strip() for k in (user_keywords or []) if k and str(k).strip()]\n",
    "    if skin_concerns: kws.extend([k.strip() for k in skin_concerns if k and str(k).strip()])\n",
    "    if weather_keywords: kws.extend([k.strip() for k in weather_keywords if k and str(k).strip()])\n",
    "    if not kws: return 0.0, {\"matched_keywords\": [], \"hit_count\": 0, \"total_keywords\": 0, \"priority_hits\": 0}\n",
    "    \n",
    "    search_text = (product_content or \"\").lower()\n",
    "    if product_keywords: search_text += \" \" + \" \".join(product_keywords).lower()\n",
    "    search_text_nospace = search_text.replace(\" \", \"\")\n",
    "    \n",
    "    priority_kws = []\n",
    "    if current_season and current_season in WEATHER_PRIORITY_KEYWORDS:\n",
    "        priority_kws = [k.lower() for k in WEATHER_PRIORITY_KEYWORDS[current_season]]\n",
    "    \n",
    "    hit_count = 0.0\n",
    "    matched_keywords = []\n",
    "    priority_matched = []\n",
    "    \n",
    "    for kw in kws:\n",
    "        kw_lower = kw.lower()\n",
    "        kw_nospace = kw_lower.replace(\" \", \"\")\n",
    "        if kw_lower in search_text or kw_nospace in search_text_nospace:\n",
    "            matched_keywords.append(kw)\n",
    "            is_priority = any(pk in kw_lower or kw_lower in pk for pk in priority_kws)\n",
    "            if is_priority:\n",
    "                hit_count += 2.0\n",
    "                priority_matched.append(kw)\n",
    "            else:\n",
    "                hit_count += 1.0\n",
    "    \n",
    "    max_possible_score = len(kws) * 2.0 if priority_kws else len(kws)\n",
    "    score = hit_count / max(max_possible_score, 1)\n",
    "    return score, {\"matched_keywords\": matched_keywords, \"hit_count\": int(hit_count), \"total_keywords\": len(kws), \"priority_hits\": len(priority_matched)}\n",
    "\n",
    "def test_recommendation_with_diagnostics(user_id: str, intent: str = \"regular\"):\n",
    "    start_time = time.time()\n",
    "    supabase = create_client(os.environ.get(\"SUPABASE_URL\"), os.environ.get(\"SUPABASE_KEY\"))\n",
    "    openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\nğŸ”§ GPU ì‚¬ìš©: {device}\")\n",
    "    cross_encoder = CrossEncoder(CE_MODEL, device=device)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\nğŸ“‹ í…ŒìŠ¤íŠ¸: {intent.capitalize()} Intent\\n{'='*80}\")\n",
    "    \n",
    "    user_resp = supabase.table(\"customers\").select(\"*\").eq(\"user_id\", user_id).execute()\n",
    "    if not user_resp.data:\n",
    "        print(f\"âŒ ìœ ì € {user_id} ì—†ìŒ\")\n",
    "        return\n",
    "    \n",
    "    user_data = user_resp.data[0]\n",
    "    user_keywords = normalize_list(user_data.get(\"keywords\", []))\n",
    "    skin_concerns = normalize_list(user_data.get(\"skin_concerns\", []))\n",
    "    expanded_keywords = expand_keywords(user_keywords)\n",
    "    expanded_concerns = expand_keywords(skin_concerns)\n",
    "    \n",
    "    print(f\"  ì›ë³¸ í‚¤ì›Œë“œ: {user_keywords}\")\n",
    "    print(f\"  ğŸ” í™•ì¥ëœ í‚¤ì›Œë“œ ({len(expanded_keywords)}ê°œ): {expanded_keywords[:10]}...\")\n",
    "    print(f\"  ğŸ©º í”¼ë¶€ê³ ë¯¼: {skin_concerns}\")\n",
    "    \n",
    "    weather_keywords = []\n",
    "    current_season = None\n",
    "    if intent == \"weather\":\n",
    "        current_season = get_current_season()\n",
    "        weather_keywords = WEATHER_KEYWORDS.get(current_season, [])\n",
    "        priority_kws = WEATHER_PRIORITY_KEYWORDS.get(current_season, [])\n",
    "        print(f\"  ğŸŒ¡ï¸ Weather: {current_season.upper()}\")\n",
    "        print(f\"  ğŸ“Œ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ({len(priority_kws)}ê°œ): {priority_kws[:8]}...\")\n",
    "        print(f\"  ğŸŒ¤ï¸ ì „ì²´ ë‚ ì”¨ í‚¤ì›Œë“œ ({len(weather_keywords)}ê°œ)\")\n",
    "    \n",
    "    all_keywords = expanded_keywords + expanded_concerns\n",
    "    if weather_keywords: all_keywords += weather_keywords\n",
    "    \n",
    "    query_text = \" \".join(all_keywords)\n",
    "    embed_resp = openai_client.embeddings.create(input=query_text, model=EMBED_MODEL)\n",
    "    query_embedding = embed_resp.data[0].embedding\n",
    "    \n",
    "    vector_resp = supabase.rpc(\"match_products\", {\"filter\": {}, \"match_count\": CANDIDATE_POOL, \"query_embedding\": query_embedding}).execute()\n",
    "    if not vector_resp.data:\n",
    "        print(\"âŒ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n  ğŸ“Š ë²¡í„° ìœ ì‚¬ë„ Top 5:\")\n",
    "    for i, p in enumerate(vector_resp.data[:5], 1):\n",
    "        print(f\"    {i}. PID {p['product_id']}: {p['similarity']:.6f}\")\n",
    "    \n",
    "    product_ids = [p[\"product_id\"] for p in vector_resp.data]\n",
    "    products_resp = supabase.table(\"products\").select(\"id, name, brand, price_final, discount_rate, keywords\").in_(\"id\", product_ids).execute()\n",
    "    products_map = {p[\"id\"]: p for p in products_resp.data}\n",
    "    \n",
    "    vector_products_resp = supabase.table(\"products_vector\").select(\"product_id, content\").in_(\"product_id\", product_ids).execute()\n",
    "    vector_content_map = {p[\"product_id\"]: p[\"content\"] for p in vector_products_resp.data}\n",
    "    \n",
    "    for vec_prod in vector_resp.data:\n",
    "        pid = vec_prod[\"product_id\"]\n",
    "        if pid in products_map:\n",
    "            vec_prod.update(products_map[pid])\n",
    "            vec_prod[\"content\"] = vector_content_map.get(pid, \"\")\n",
    "    \n",
    "    print(f\"\\n  ğŸ”¥ Cross-Encoder ì‹¤í–‰ ì¤‘... ({len(vector_resp.data)} products)\")\n",
    "    ce_start = time.time()\n",
    "    pairs = [[query_text, p.get(\"content\", \"\")] for p in vector_resp.data]\n",
    "    ce_scores = cross_encoder.predict(pairs, show_progress_bar=False)\n",
    "    print(f\"  âœ… Cross-Encoder ì™„ë£Œ ({time.time() - ce_start:.2f}ì´ˆ)\")\n",
    "    \n",
    "    scored_products = []\n",
    "    sim_map = {p[\"product_id\"]: p[\"similarity\"] for p in vector_resp.data}\n",
    "    \n",
    "    for i, p in enumerate(vector_resp.data):\n",
    "        pid = p[\"product_id\"]\n",
    "        ce_score = float(ce_scores[i])\n",
    "        product_content = p.get(\"content\", \"\")\n",
    "        product_keywords = normalize_list(p.get(\"keywords\"))\n",
    "        \n",
    "        kwb, kw_details = keyword_bonus(\n",
    "            user_keywords=expanded_keywords,\n",
    "            product_content=product_content,\n",
    "            product_keywords=product_keywords,\n",
    "            skin_concerns=expanded_concerns,\n",
    "            weather_keywords=weather_keywords if intent == \"weather\" else None,\n",
    "            current_season=current_season if intent == \"weather\" else None\n",
    "        )\n",
    "        \n",
    "        final_score = ce_score + KW_BONUS_ALPHA * kwb\n",
    "        scored_products.append({\n",
    "            \"id\": pid,\n",
    "            \"name\": p.get(\"name\", \"\"),\n",
    "            \"brand_name\": p.get(\"brand\", \"\"),\n",
    "            \"price\": p.get(\"price_final\", 0),\n",
    "            \"discount_rate\": p.get(\"discount_rate\", 0),\n",
    "            \"product_keywords\": product_keywords,\n",
    "            \"ce_score\": float(ce_score),\n",
    "            \"kw_bonus\": float(kwb),\n",
    "            \"kw_details\": kw_details,\n",
    "            \"final_score\": float(final_score),\n",
    "            \"similarity\": float(sim_map.get(pid, 0.0)),\n",
    "        })\n",
    "    \n",
    "    if intent == \"event\":\n",
    "        scored_products.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
    "        if len(scored_products) >= 5:\n",
    "            top_5 = scored_products[:5]\n",
    "            top_5.sort(key=lambda x: x[\"discount_rate\"], reverse=True)\n",
    "            scored_products = top_5 + scored_products[5:]\n",
    "        print(f\"\\n  ğŸ Event Intent: Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„ \")\n",
    "    else:\n",
    "        scored_products.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\nğŸ” Top 5 ì œí’ˆ í‚¤ì›Œë“œ ë§¤ì¹­ ë¹„êµ\\n{'='*80}\\n\")\n",
    "    \n",
    "    for rank, p in enumerate(scored_products[:5], 1):\n",
    "        kw_details = p[\"kw_details\"]\n",
    "        match_rate = kw_details[\"hit_count\"] / (kw_details[\"total_keywords\"] * 2) * 100 if intent == \"weather\" and kw_details[\"total_keywords\"] > 0 else kw_details[\"hit_count\"] / kw_details[\"total_keywords\"] * 100 if kw_details[\"total_keywords\"] > 0 else 0\n",
    "        \n",
    "        print(f\"  {rank}ìœ„: PID {p['id']} - {p['name'][:40]}...\")\n",
    "        print(f\"      ë¸Œëœë“œ: {p['brand_name']}\")\n",
    "        print(f\"      ì œí’ˆ í‚¤ì›Œë“œ: {p['product_keywords'][:5]}...\")\n",
    "        print(f\"      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "        print(f\"      ë²¡í„° ìœ ì‚¬ë„: {p['similarity']:.6f}\")\n",
    "        print(f\"      CE ì ìˆ˜: {p['ce_score']:.6f}\")\n",
    "        \n",
    "        if intent == \"weather\" and kw_details.get(\"priority_hits\", 0) > 0:\n",
    "            print(f\"      í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤: {p['kw_bonus']:.6f} (ê°€ì¤‘ì¹˜ í•©ì‚°: {kw_details['hit_count']}, ìš°ì„ ìˆœìœ„ {kw_details['priority_hits']}ê°œ Ã—2ë°°)\")\n",
    "        else:\n",
    "            print(f\"      í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤: {p['kw_bonus']:.6f} ({match_rate:.0f}% ë§¤ì¹­, {kw_details['hit_count']}/{kw_details['total_keywords']})\")\n",
    "        \n",
    "        print(f\"      ìµœì¢… ì ìˆ˜: {p['final_score']:.6f}\")\n",
    "        \n",
    "        if kw_details[\"matched_keywords\"]:\n",
    "            matched_str = \"', '\".join(kw_details[\"matched_keywords\"][:15])\n",
    "            print(f\"      âœ… ë§¤ì¹­ í‚¤ì›Œë“œ ({len(kw_details['matched_keywords'])}ê°œ): '{matched_str}'...\\n\")\n",
    "        else:\n",
    "            print(f\"      âŒ ë§¤ì¹­ í‚¤ì›Œë“œ ì—†ìŒ\\n\")\n",
    "    \n",
    "    top_product = scored_products[0]\n",
    "    kw_details = top_product[\"kw_details\"]\n",
    "    match_rate = kw_details[\"hit_count\"] / (kw_details[\"total_keywords\"] * 2) * 100 if intent == \"weather\" and kw_details[\"total_keywords\"] > 0 else kw_details[\"hit_count\"] / kw_details[\"total_keywords\"] * 100 if kw_details[\"total_keywords\"] > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\nğŸ† ìµœì¢… ì¶”ì²œ ì œí’ˆ\\n{'='*80}\")\n",
    "    print(f\"  ğŸ“¦ {top_product['name']}\")\n",
    "    print(f\"  ğŸ·ï¸  ë¸Œëœë“œ: {top_product['brand_name']}\")\n",
    "    print(f\"  ğŸ’° ê°€ê²©: {top_product['price']:,}ì› (í• ì¸: {top_product['discount_rate']}%)\")\n",
    "    print(f\"\\n  ğŸ“Š ì ìˆ˜:\")\n",
    "    print(f\"     ë²¡í„° ìœ ì‚¬ë„: {top_product['similarity']:.6f}\")\n",
    "    print(f\"     CE ì ìˆ˜: {top_product['ce_score']:.6f}\")\n",
    "    print(f\"     í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤: {top_product['kw_bonus']:.6f}\")\n",
    "    print(f\"     ìµœì¢… ì ìˆ˜: {top_product['final_score']:.6f}\")\n",
    "    print(f\"     ê³„ì‚°ì‹: {top_product['final_score']:.4f} = {top_product['ce_score']:.4f} + ({KW_BONUS_ALPHA} Ã— {top_product['kw_bonus']:.4f})\")\n",
    "    print(f\"\\n  ğŸ” í‚¤ì›Œë“œ ë§¤ì¹­:\")\n",
    "    print(f\"     ì „ì²´ í‚¤ì›Œë“œ: {kw_details['total_keywords']}ê°œ\")\n",
    "    print(f\"     ë§¤ì¹­ëœ í‚¤ì›Œë“œ: {len(kw_details['matched_keywords'])}ê°œ\")\n",
    "    \n",
    "    if intent == \"weather\" and kw_details.get(\"priority_hits\", 0) > 0:\n",
    "        print(f\"     ğŸŒŸ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ: {kw_details['priority_hits']}ê°œ (2ë°° ê°€ì¤‘ì¹˜)\")\n",
    "        print(f\"     ê°€ì¤‘ì¹˜ í•©ì‚°: {kw_details['hit_count']} (ì¼ë°˜ {len(kw_details['matched_keywords']) - kw_details['priority_hits']} + ìš°ì„ ìˆœìœ„ {kw_details['priority_hits']}Ã—2)\")\n",
    "    \n",
    "    print(f\"     ë§¤ì¹­ë¥ : {match_rate:.1f}%\")\n",
    "    \n",
    "    if kw_details[\"matched_keywords\"]:\n",
    "        print(f\"\\n  âœ… ë§¤ì¹­ëœ í‚¤ì›Œë“œ ({len(kw_details['matched_keywords'])}ê°œ):\")\n",
    "        for kw in kw_details[\"matched_keywords\"][:20]:\n",
    "            print(f\"     - '{kw}'\")\n",
    "    \n",
    "    print(f\"\\n  ğŸ’¡ í‰ê°€:\")\n",
    "    if match_rate < 15:\n",
    "        print(f\"     âš ï¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë‚®ìŒ ({match_rate:.0f}%)\")\n",
    "    elif match_rate < 30:\n",
    "        print(f\"     âœ… í‚¤ì›Œë“œ ë§¤ì¹­ ë³´í†µ ({match_rate:.0f}%)\")\n",
    "    else:\n",
    "        print(f\"     ğŸ¯ í‚¤ì›Œë“œ ë§¤ì¹­ ìš°ìˆ˜ ({match_rate:.0f}%)\")\n",
    "    \n",
    "    if top_product['ce_score'] > 0.6:\n",
    "        print(f\"     âœ… ì¶”ì²œ íƒ€ë‹¹í•¨ - Cross-Encoder ì ìˆ˜ ë†’ìŒ\")\n",
    "    else:\n",
    "        print(f\"     âš ï¸ ì¬ê²€í†  ê¶Œì¥\")\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  ì†Œìš”ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ\\n\")\n",
    "\n",
    "print(\"\\n\" + \"ğŸ”µ\" * 40)\n",
    "print(\"ì‹œë‚˜ë¦¬ì˜¤ 1: Regular Intent\")\n",
    "print(\"ğŸ”µ\" * 40)\n",
    "test_recommendation_with_diagnostics(\"user_001\", intent=\"regular\")\n",
    "\n",
    "print(\"\\n\\n\" + \"ğŸŸ¡\" * 40)\n",
    "print(\"ì‹œë‚˜ë¦¬ì˜¤ 2: Weather Intent (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ 2ë°° ê°€ì¤‘ì¹˜)\")\n",
    "print(\"ğŸŸ¡\" * 40)\n",
    "test_recommendation_with_diagnostics(\"user_001\", intent=\"weather\")\n",
    "\n",
    "print(\"\\n\\n\" + \"ğŸ\" * 40)\n",
    "print(\"ì‹œë‚˜ë¦¬ì˜¤ 3: Event Intent (Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„ )\")\n",
    "print(\"ğŸ\" * 40)\n",
    "test_recommendation_with_diagnostics(\"user_001\", intent=\"event\")\n",
    "\n",
    "print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
