import os
import json
from typing import Dict, Any, List, Optional, Tuple
from openai import OpenAI
import httpx
from config import (
    settings,
    # Cross-Encoder ì„¤ì •
    TOP_K, CANDIDATE_POOL, EMBED_MODEL, EMBED_DIM, CE_MODEL, KW_BONUS_ALPHA,
    CUSTOMER_ID_COL, PRODUCT_VECTOR_FK_COL,
    # ë™ì˜ì–´ ë§¤í•‘
    SKIN_TYPE_MAP, CONCERN_MAP, TONE_MAP,
    # í‚¤ì›Œë“œ ë²ˆì—­
    KEYWORD_TRANSLATION,
    # ë‚ ì”¨ í‚¤ì›Œë“œ
    WEATHER_KEYWORDS, WEATHER_PRIORITY_KEYWORDS
)
from sentence_transformers import CrossEncoder
import torch
from datetime import datetime

# Cross-Encoder ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
_cross_encoder_cache = None

client = OpenAI(api_key=settings.OPENAI_API_KEY)

def get_cross_encoder() -> CrossEncoder:
    """Cross-Encoderë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _cross_encoder_cache
    if _cross_encoder_cache is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"[CrossEncoder] loading: {CE_MODEL} on device={device}")
        _cross_encoder_cache = CrossEncoder(CE_MODEL, device=device)
    return _cross_encoder_cache


def normalize_list(v: Any) -> List[str]:
    """ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”"""
    if v is None:
        return []
    if isinstance(v, list):
        return [str(x).strip() for x in v if str(x).strip()]
    if isinstance(v, str):
        s = v.strip()
        if s.startswith("{") and s.endswith("}"):
            s = s[1:-1]
        return [x.strip().strip('"') for x in s.split(",") if x.strip()]
    return [str(v).strip()]


def with_kr(items: List[str], mapping: Dict[str, str]) -> List[str]:
    """ì˜ì–´ í‚¤ì›Œë“œì— í•œê¸€ ë§¤í•‘ ì¶”ê°€"""
    out = []
    for x in items:
        k = mapping.get(x)
        out.append(f"{x}({k})" if k else x)
    return out


def build_user_query_text(customer: Dict[str, Any]) -> str:
    """ìœ ì € ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±"""
    skin_types = with_kr(normalize_list(customer.get("skin_type")), SKIN_TYPE_MAP)
    concerns = with_kr(normalize_list(customer.get("skin_concerns")), CONCERN_MAP)
    keywords = normalize_list(customer.get("keywords"))
    
    # preferred_toneì´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ (DB ìŠ¤í‚¤ë§ˆ ì°¨ì´)
    tone = customer.get("preferred_tone")
    if isinstance(tone, list):
        tone = tone[0] if tone else None
    
    tone_kr = TONE_MAP.get(tone, tone) if tone else None

    lines = [
        "ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ì¶”ì²œ ì¿¼ë¦¬ (í‚¤ì›Œë“œ ìµœìš°ì„ )",
        "",
        "[ì¤‘ìš” í‚¤ì›Œë“œ TOP - ìµœìš°ì„  ë°˜ì˜]",
        f"- {', '.join(keywords)}" if keywords else "- (ì—†ìŒ)",
        "â€» ìœ„ í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” íš¨ëŠ¥/íŠ¹ì§•/ì œí’ˆ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì œí’ˆì„ ìµœìš°ì„ ìœ¼ë¡œ í‰ê°€í•œë‹¤.",
        "",
        "[í”¼ë¶€íƒ€ì…]",
        f"- {', '.join(skin_types)}" if skin_types else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í”¼ë¶€ê³ ë¯¼]",
        f"- {', '.join(concerns)}" if concerns else "- ì •ë³´ ì—†ìŒ",
        "",
        "[ì¶”êµ¬ í†¤]",
        f"- {tone_kr}" if tone_kr else "- ì •ë³´ ì—†ìŒ",
        "",
        "[í‰ê°€ ê¸°ì¤€ ì¬ê°•ì¡°]",
        f"- í•µì‹¬ í‚¤ì›Œë“œ({', '.join(keywords)})ì™€ ì—°ê´€ì„±ì´ ë†’ì€ ì œí’ˆì„ ìš°ì„  ì¶”ì²œ" if keywords else "- í‚¤ì›Œë“œ ê¸°ë°˜ ìš°ì„  ì¶”ì²œ",
    ]
    return "\n".join(lines)


def embed_text(oa: OpenAI, text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    res = oa.embeddings.create(
        model=EMBED_MODEL,
        input=[text],
        encoding_format="float",
    )
    emb = res.data[0].embedding
    if len(emb) != EMBED_DIM:
        raise ValueError(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: got {len(emb)} expected {EMBED_DIM}")
    return emb


def truncate_for_ce(text: str, max_chars: int = 1800) -> str:
    """Cross-Encoder ì…ë ¥ ê¸¸ì´ ì œí•œ"""
    text = text or ""
    return text if len(text) <= max_chars else text[:max_chars]


def expand_keywords(keywords: List[str]) -> List[str]:
    """ì˜ì–´ í‚¤ì›Œë“œë¥¼ í•œê¸€ ë™ì˜ì–´ë¡œ í™•ì¥í•˜ì—¬ ë§¤ì¹­ë¥  í–¥ìƒ"""
    expanded = []
    for kw in keywords:
        # ì›ë³¸ í‚¤ì›Œë“œ ì¶”ê°€
        expanded.append(kw)
        
        # ì •ê·œí™”: ì†Œë¬¸ì ë³€í™˜, ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        normalized = kw.lower().replace("_", "").replace("-", "").replace(" ", "")
        
        # ë§¤í•‘ëœ í•œê¸€ ë™ì˜ì–´ ì¶”ê°€
        if normalized in KEYWORD_TRANSLATION:
            expanded.extend(KEYWORD_TRANSLATION[normalized])
    
    return expanded


def get_current_season() -> str:
    """í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì¦Œ ë°˜í™˜"""
    month = datetime.now().month
    if month in [3, 4, 5]:
        return "spring"
    elif month in [6, 7, 8]:
        return "summer"
    elif month in [9, 10, 11]:
        return "fall"
    else:  # 12, 1, 2
        return "winter"


def keyword_bonus(
    user_keywords: List[str], 
    product_content: str, 
    product_keywords: List[str], 
    skin_concerns: List[str] = None,
    weather_keywords: List[str] = None,
    current_season: str = None
) -> Tuple[float, Dict[str, Any]]:
    """í‚¤ì›Œë“œ ë§¤ì¹­ ë³´ë„ˆìŠ¤ ê³„ì‚° (0~1) - ë‹¨ìˆœ ì¹´ìš´íŠ¸ ë°©ì‹ + ë‚ ì”¨ ìš°ì„ ìˆœìœ„ ê°€ì¤‘ì¹˜
    
    ìœ ì €ì˜ í‚¤ì›Œë“œ + í”¼ë¶€ê³ ë¯¼ì´ ì œí’ˆ ë³¸ë¬¸ + ì œí’ˆ í‚¤ì›Œë“œì—ì„œ ëª‡ ë²ˆ ë‚˜ì˜¤ëŠ”ì§€ ì¹´ìš´íŠ¸
    
    Args:
        user_keywords: ìœ ì €ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (í™•ì¥ëœ ê²ƒ)
        product_content: ì œí’ˆ ë³¸ë¬¸ (products_vector.content)
        product_keywords: ì œí’ˆ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (products.keywords)
        skin_concerns: ìœ ì €ì˜ í”¼ë¶€ê³ ë¯¼ (ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ)
        weather_keywords: ë‚ ì”¨/ì‹œì¦Œ ê´€ë ¨ í‚¤ì›Œë“œ (intent=weatherì¼ ë•Œ)
        current_season: í˜„ì¬ ê³„ì ˆ (spring/summer/fall/winter)
    
    Returns:
        (score, details): 0~1 ì ìˆ˜ì™€ ìƒì„¸ ì •ë³´
    """
    # ê²€ìƒ‰í•  í‚¤ì›Œë“œ ìˆ˜ì§‘
    kws = [k.strip() for k in (user_keywords or []) if k and str(k).strip()]
    
    # í”¼ë¶€ê³ ë¯¼ ì¶”ê°€
    if skin_concerns:
        kws.extend([k.strip() for k in skin_concerns if k and str(k).strip()])
    
    # weather intentì¼ ê²½ìš° weather_keywords ì¶”ê°€
    if weather_keywords:
        kws.extend([k.strip() for k in weather_keywords if k and str(k).strip()])
    
    if not kws:
        return 0.0, {"matched_keywords": [], "hit_count": 0, "total_keywords": 0, "priority_hits": 0}

    # ê²€ìƒ‰ ëŒ€ìƒ: ì œí’ˆ ë³¸ë¬¸ + ì œí’ˆ í‚¤ì›Œë“œ í•©ì¹˜ê¸°
    search_text = (product_content or "").lower()
    if product_keywords:
        search_text += " " + " ".join([str(k).lower() for k in product_keywords])
    
    # ë„ì–´ì“°ê¸° ì œê±°í•œ ì •ê·œí™” ë²„ì „
    search_text_normalized = search_text.replace(" ", "")

    # ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
    priority_kws = []
    if current_season and current_season in WEATHER_PRIORITY_KEYWORDS:
        priority_kws = [k.lower() for k in WEATHER_PRIORITY_KEYWORDS[current_season]]

    # í‚¤ì›Œë“œ ë§¤ì¹­ ì¹´ìš´íŠ¸ (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œëŠ” 2ë°° ê°€ì¤‘ì¹˜)
    hit_count = 0.0
    matched_keywords = []
    priority_matched = []
    
    for kw in kws:
        k = kw.lower()
        k_normalized = k.replace(" ", "")
        
        # ì›ë³¸ ë§¤ì¹­ OR ì •ê·œí™” ë§¤ì¹­
        if (k in search_text) or (k_normalized in search_text_normalized):
            matched_keywords.append(kw)
            
            # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œì¸ì§€ í™•ì¸ (ê³„ì ˆë³„ í•µì‹¬ í‚¤ì›Œë“œ)
            is_priority = any(pk in k or k in pk for pk in priority_kws)
            
            if is_priority:
                hit_count += 2.0  # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œëŠ” 2ë°° ê°€ì¤‘ì¹˜
                priority_matched.append(kw)
            else:
                hit_count += 1.0  # ì¼ë°˜ í‚¤ì›Œë“œ

    # 0~1 ì •ê·œí™” (ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€ê°’ ì¡°ì •)
    # ëª¨ë“  í‚¤ì›Œë“œê°€ ìš°ì„ ìˆœìœ„ë¼ë©´ max = len(kws) * 2
    max_possible_score = len(kws) * 2.0 if priority_kws else len(kws)
    score = hit_count / max(max_possible_score, 1)
    
    details = {
        "matched_keywords": matched_keywords,
        "hit_count": int(hit_count),  # ì‹¤ì œ ê°€ì¤‘ì¹˜ ì ìš©ëœ ê°’
        "total_keywords": len(kws),
        "priority_hits": len(priority_matched)  # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë§¤ì¹­ ìˆ˜
    }
    
    return float(min(1.0, max(0.0, score))), details


async def fetch_products_from_supabase() -> Dict[str, str]:
    """
    Fetch products from Supabase and format them for the LLM.
    (Deprecated - ì´ì œ recommend_product_with_brands ì‚¬ìš©)
    """
    return {}

    # url = f"{settings.SUPABASE_URL}/rest/v1/products"
    # headers = {
    #     "apikey": settings.SUPABASE_KEY,
    #     "Authorization": f"Bearer {settings.SUPABASE_KEY}",
    # }

    # try:
    #     async with httpx.AsyncClient() as http_client:
    #         response = await http_client.get(url, headers=headers)
    #         response.raise_for_status()
    #         products_data = response.json()
            
    #         # Format: "ID": "Name (Brand, Category, Description)"
    #         formatted_products = {}
    #         full_data = {}  # Store full product data
    #         for p in products_data:
    #             # Adjust field names based on actual DB schema
    #             # Schema: id, product_code, brand, name, category_major, category_middle, category_small, 
    #             # price_original, price_final, discount_rate, review_score, review_count, features, analytics, keywords
                
    #             p_id = p.get("product_code") or str(p.get("id"))
    #             name = p.get("name")
    #             brand = p.get("brand", "")
                
    #             # Construct category string
    #             cats = [p.get("category_major"), p.get("category_middle"), p.get("category_small")]
    #             category = " > ".join([c for c in cats if c])
                
    #             # Construct description from keywords and features
    #             keywords = p.get("keywords", "")
    #             price = p.get("price_final")
    #             review_score = p.get("review_score")
                
    #             desc_parts = []
    #             if keywords:
    #                 desc_parts.append(f"Keywords: {keywords}")
    #             if price:
    #                 desc_parts.append(f"Price: {price}")
    #             if review_score:
    #                 desc_parts.append(f"Rating: {review_score}")
                
    #             desc = ", ".join(desc_parts)
                
    #             if p_id and name:
    #                 info = f"{name} (Brand: {brand}, Category: {category}, {desc})"
    #                 formatted_products[p_id] = info
    #                 # Store full product data
    #                 full_data[p_id] = p
            
    #         PRODUCTS_CACHE = formatted_products
    #         PRODUCTS_FULL_DATA = full_data
            
    #         # Debug: Print first 3 products to verify format
    #         print("DEBUG: Sample products from DB:")
    #         for i, (pid, info) in enumerate(formatted_products.items()):
    #             if i >= 3: break
    #             print(f" - {pid}: {info}")
                
    #         return formatted_products
            
    # except Exception as e:
    #     print(f"Failed to fetch products from Supabase: {e}")
    #     # Fallback to empty dict or hardcoded list if needed
    #     return {}

async def recommend_product_with_brands(
    user_id: str,
    user_data: Any,
    target_brands: List[str] = None,
    top_k: int = 1,
    intent: str = ""
) -> Optional[Dict[str, Any]]:
    """
    ìœ ì € IDì™€ ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ Cross-Encoder ê¸°ë°˜ìœ¼ë¡œ ìµœê³ ì˜ ìƒí’ˆì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        user_data: CustomerProfile ê°ì²´ (user_dataì—ì„œ ì¶”ì¶œí•œ ì •ë³´)
        target_brands: ì¶”ì²œí•  ë¸Œëœë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ë¸Œëœë“œ)
        top_k: ë°˜í™˜í•  ìƒí’ˆ ê°œìˆ˜ (ê¸°ë³¸ê°’: 1)
        intent: ì¶”ì²œ ì˜ë„ ("": regular, "event": í• ì¸ìœ¨ ë†’ì€ ì œí’ˆ, "weather": ë‚ ì”¨ë³„ ì œí’ˆ)
        
    Returns:
        ì¶”ì²œ ìƒí’ˆ ì •ë³´ dict ë˜ëŠ” None
    """
    try:
        # Supabase ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        from supabase import create_client, Client
        sb: Client = create_client(settings.SUPABASE_URL, settings.SUPABASE_KEY)
        oa = OpenAI(api_key=settings.OPENAI_API_KEY)
        ce = get_cross_encoder()
        
        # 1) ê³ ê° ì •ë³´ ì¡°íšŒ
        customer_resp = (
            sb.table("customers")
            .select("user_id, skin_type, skin_concerns, keywords, preferred_tone")
            .eq(CUSTOMER_ID_COL, user_id)
            .limit(1)
            .execute()
        )

        print(f"customer_resp: {customer_resp}")

        
        if not customer_resp.data:
            print(f"[WARN] customersì—ì„œ {CUSTOMER_ID_COL}={user_id}ë¥¼ ì°¾ì§€ ëª»í•¨")
            return None
        
        customer = customer_resp.data[0]
        user_keywords_raw = normalize_list(customer.get("keywords"))
        
        # í‚¤ì›Œë“œ í™•ì¥: ì˜ì–´ -> í•œê¸€ ë™ì˜ì–´ ì¶”ê°€
        user_keywords = expand_keywords(user_keywords_raw)
        print(f"  ğŸ” í‚¤ì›Œë“œ í™•ì¥: {user_keywords_raw} â†’ {len(user_keywords)}ê°œ")
        
        # [Fix] í”¼ë¶€ ê³ ë¯¼ ì •ì˜ (í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ê³„ì‚°ìš©)
        concerns = with_kr(normalize_list(customer.get("skin_concerns")), CONCERN_MAP)

        # intent ì²˜ë¦¬: weatherì¼ ê²½ìš° ì‹œì¦Œë³„ í‚¤ì›Œë“œ ì¶”ê°€
        weather_keywords = []
        if intent == "weather":
            current_season = get_current_season()
            weather_keywords = WEATHER_KEYWORDS.get(current_season, [])
            print(f"  ğŸŒ¡ï¸ Weather Intent: {current_season} season - í‚¤ì›Œë“œ: {weather_keywords[:3]}...")
        
        # 2) ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
        query_text = build_user_query_text(customer)
        
        # 3) ì„ë² ë”© ìƒì„±
        query_emb = embed_text(oa, query_text)
        
        # 4) ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í›„ë³´ í’€) - ë¸Œëœë“œ í•„í„°ë§ ì ìš©
        if target_brands and len(target_brands) > 0:
            # ë¸Œëœë“œê°€ ì§€ì •ëœ ê²½ìš°
            print(f"\nğŸ” [RPC Search] ë¸Œëœë“œ ì§€ì • ê²€ìƒ‰: {target_brands}")
            
            rpc_payload = {
                "query_embedding": query_emb,
                "match_count": CANDIDATE_POOL,
                "filter_brands": target_brands
            }
            
            try:
                response = sb.rpc('match_products', rpc_payload).execute()
                matches = response.data or []
                
                print(f"ğŸ“Š [RPC Response] ë¸Œëœë“œ í•„í„°ë§ ê²€ìƒ‰ ê²°ê³¼: {len(matches)}ê°œ")
                
                # ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 3ê°œ)
                if matches:
                    print(f"  - ìƒìœ„ 3ê°œ ìƒ˜í”Œ:")
                    for i, item in enumerate(matches[:3], 1):
                        print(f"    {i}. ID: {item.get('product_id')}, ìœ ì‚¬ë„: {item.get('similarity', 0):.4f}")
                
            except Exception as e:
                print(f"âŒ [RPC Error] ë¸Œëœë“œ í•„í„°ë§ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                matches = []
        else:
            # ë¸Œëœë“œ ì§€ì • ì—†ìŒ - ì¼ë°˜ ê²€ìƒ‰
            print(f"\nğŸ” [RPC Search] ë¸Œëœë“œ ë¯¸ì§€ì • - ì „ì²´ ê²€ìƒ‰ (pool={CANDIDATE_POOL})")
            
            rpc_payload = {
                "filter": {},
                "match_count": CANDIDATE_POOL,
                "query_embedding": query_emb,
            }
            
            match_resp = sb.rpc("match_products", rpc_payload).execute()
            matches = match_resp.data or []
            
            print(f"ğŸ“Š [RPC Response] ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼: {len(matches)}ê°œ")
        
        if not matches:
            print("âŒ [ERROR] ìµœì¢… ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        matches.sort(key=lambda m: float(m.get("similarity", 0.0)), reverse=True)
        candidate_ids = [m["product_id"] for m in matches]
        sim_map = {m["product_id"]: float(m["similarity"]) for m in matches}
        
        print(f"\nğŸ“‹ [Candidate Pool] ìµœì¢… í›„ë³´:")
        print(f"  - í›„ë³´ ID ìˆ˜: {len(candidate_ids)}ê°œ")
        print(f"  - ìƒìœ„ 5ê°œ ID: {candidate_ids[:5]}")
        
        # 5) products ìƒì„¸ ì •ë³´ ì¡°íšŒ
        # RPCì—ì„œ ì´ë¯¸ ë¸Œëœë“œ í•„í„°ë§ì´ ì ìš©ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ í•„í„° ë¶ˆí•„ìš”
        print(f"\nğŸ—ƒï¸ [Products Table] ìƒì„¸ ì •ë³´ ì¡°íšŒ:")
        products_resp = (
            sb.table("products")
            .select("id, brand, name, category_major, category_middle, category_small, price_final, discount_rate, review_score, review_count")
            .in_("id", candidate_ids)
            .execute()
        )
        products = products_resp.data or []
        
        print(f"\nğŸ“¦ [Products Result] ì¡°íšŒ ê²°ê³¼:")
        print(f"  - ì¡°íšŒëœ ì œí’ˆ ìˆ˜: {len(products)}ê°œ")
        if products:
            print(f"  - ë¸Œëœë“œ ë¶„í¬: {dict((b, sum(1 for p in products if p.get('brand') == b)) for b in set(p.get('brand') for p in products))}")
            print(f"  - ìƒìœ„ 3ê°œ:")
            for i, p in enumerate(products[:3], 1):
                print(f"    {i}. [{p.get('brand')}] {p.get('name')[:30]}... (ID={p.get('id')})")
        
        if not products:
            print(f"\nâŒ [ERROR] products í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨")
            if target_brands:
                print(f"  â†’ ë¸Œëœë“œ í•„í„°({target_brands}) ë•Œë¬¸ì— ì œí’ˆì´ ì—†ì„ ìˆ˜ ìˆìŒ")
                print(f"  â†’ candidate_idsì—ëŠ” {len(candidate_ids)}ê°œê°€ ìˆì—ˆì§€ë§Œ í•´ë‹¹ ë¸Œëœë“œ ì œí’ˆì´ ì—†ìŒ")
            else:
                print(f"  â†’ candidate_ids={candidate_ids[:5]}... ì¤‘ products í…Œì´ë¸”ì— ì—†ëŠ” IDë“¤")
            return None
        
        prod_map = {p["id"]: p for p in products}
        filtered_ids = list(prod_map.keys())
        
        print(f"\nâœ… [Products Filtered] ìµœì¢… ì œí’ˆ í’€:")
        print(f"  - í•„í„°ë§ í›„ ì œí’ˆ ìˆ˜: {len(filtered_ids)}ê°œ")
        
        # 6) products_vector content ê°€ì ¸ì˜¤ê¸°
        pv_resp = (
            sb.table("products_vector")
            .select(f"{PRODUCT_VECTOR_FK_COL}, content")
            .in_(PRODUCT_VECTOR_FK_COL, filtered_ids)
            .execute()
        )
        pv_rows = pv_resp.data or []
        pv_map = {r[PRODUCT_VECTOR_FK_COL]: r.get("content") for r in pv_rows}
        
        # 7) Cross-Encoder rerank + keyword bonus
        pairs: List[Tuple[str, str]] = []
        valid_ids: List[int] = []
        
        for pid in filtered_ids:
            content = pv_map.get(pid)
            if not content:
                continue
            valid_ids.append(pid)
            pairs.append((truncate_for_ce(query_text), truncate_for_ce(content)))
        
        if not pairs:
            print("[WARN] ë¸Œëœë“œ í•„í„°ë§ í›„ products_vector.contentê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
        
        ce_scores = ce.predict(pairs)
        
        reranked = []
        for pid, ce_score in zip(valid_ids, ce_scores):
            content = pv_map.get(pid, "")
            p = prod_map.get(pid)
            
            # ì œí’ˆ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            product_keywords = normalize_list(p.get("keywords"))
            
            # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ê³„ì‚° (í”¼ë¶€ê³ ë¯¼ + ë‚ ì”¨ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ í¬í•¨)
            kwb, kw_details = keyword_bonus(
                user_keywords=user_keywords,
                product_content=content,
                product_keywords=product_keywords,
                skin_concerns=concerns,
                weather_keywords=weather_keywords if intent == "weather" else None,
                current_season=current_season if intent == "weather" else None
            )
            
            final_score = float(ce_score) + KW_BONUS_ALPHA * kwb
            
            reranked.append({
                "product_id": str(pid),
                "brand": p.get("brand"),
                "name": p.get("name"),
                "category_major": p.get("category_major"),
                "category_middle": p.get("category_middle"),
                "category_small": p.get("category_small"),
                "price_final": p.get("price_final"),
                "discount_rate": p.get("discount_rate"),
                "review_score": p.get("review_score"),
                "review_count": p.get("review_count"),
                "ce_score": float(ce_score),
                "kw_bonus": float(kwb),
                "final_score": float(final_score),
                "similarity": float(sim_map.get(pid, 0.0)),
            })
        
        # intentì— ë”°ë¥¸ ì •ë ¬
        if intent == "event":
            # Event Intent: final_scoreë¡œ Top 5 ì¶”ì¶œ í›„, Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„ 
            reranked.sort(key=lambda r: r["final_score"], reverse=True)
            if len(reranked) >= 5:
                top_5 = reranked[:5]
                top_5.sort(key=lambda r: (r.get("discount_rate") or 0), reverse=True)
                reranked = top_5 + reranked[5:]
            print(f"  ğŸ Event Intent: Top 5 ì¤‘ í• ì¸ìœ¨ ìš°ì„  (1ìœ„ í• ì¸ìœ¨: {reranked[0].get('discount_rate', 0)}%)")
        else:
            # regular ë˜ëŠ” weather: final_scoreë¡œ ì •ë ¬
            reranked.sort(key=lambda r: r["final_score"], reverse=True)
        
        # 9) ë””ë²„ê·¸ ì¶œë ¥ (ìƒìœ„ 3ê°œ)
        if reranked:
            print(f"\nğŸ† [Final Ranking] Top 3 ì¶”ì²œ ê²°ê³¼:")
            for i, r in enumerate(reranked[:3], 1):
                print(f"  {i}. [{r.get('brand')}] {r['name'][:30]}...")
                print(f"     - CE: {r['ce_score']:.4f}, KW: {r['kw_bonus']:.3f}, Final: {r['final_score']:.4f}")
                print(f"     - í• ì¸: {r.get('discount_rate', 0)}%, ë¦¬ë·°: {r.get('review_score', 0)}â­")
            
            # ìµœì¢… 1ìœ„ ì œí’ˆ ìƒì„¸ ì •ë³´
            winner = reranked[0]
            print(f"\nğŸ¯ [Winner] ìµœì¢… ì„ íƒ:")
            print(f"  - Brand: {winner.get('brand')} â† {'âœ… ì¡´ì¬' if winner.get('brand') else 'âŒ ëˆ„ë½'}")
            print(f"  - Name: {winner.get('name')}")
            print(f"  - Product ID: {winner.get('product_id')}")
        
        # 8) top_k ê°œìˆ˜ë§Œí¼ ë°˜í™˜
        if top_k == 1:
            result = reranked[0] if reranked else None
            if result:
                # ë°˜í™˜ ì „ brand í•„ë“œ ì¬í™•ì¸
                if not result.get('brand'):
                    print(f"\nâš ï¸ [CRITICAL] ë°˜í™˜í•  ì œí’ˆì— brandê°€ ì—†ìŒ! prod_map í™•ì¸:")
                    pid = result.get('product_id')
                    if pid and int(pid) in prod_map:
                        print(f"  - prod_map[{pid}]: {prod_map[int(pid)]}")
            return result
        else:
            return reranked[:top_k]
            
    except Exception as e:
        print(f"âŒ ìƒí’ˆ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


async def get_recommendation(request_data: Any) -> Dict[str, Any]:
    """
    Get recommendation using Cross-Encoder based system.
    """
    user_id = request_data.user_id
    intention = getattr(request_data, 'intention', None) or ""
    user_data = request_data.user_data
    target_brands = getattr(request_data, 'target_brand', None)

    print(f"user_data: {user_data}, target_brands: {target_brands}")
    
    print(f"\nğŸ¯ ì¶”ì²œ ìš”ì²­ ìˆ˜ì‹ :")
    print(f"  - User ID: {user_id}")
    print(f"  - Intention: {intention}")
    print(f"  - Target Brands: {target_brands}")
    
    # Cross-Encoder ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ í˜¸ì¶œ
    recommendation = await recommend_product_with_brands(
        user_id=user_id,
        user_data=user_data,
        target_brands=target_brands if target_brands else [],
        top_k=1,
        intent=intention
    )
    
    if recommendation:
        print(f"  âœ… ìƒí’ˆ ì¶”ì²œ ì„±ê³µ: {recommendation['name']} (ID: {recommendation['product_id']})")
        print(f"  ğŸ“Š Score: ce={recommendation['ce_score']:.4f}, kw_bonus={recommendation['kw_bonus']:.3f}, final={recommendation['final_score']:.4f}")
        
        result = {
            "product_id": recommendation['product_id'],
            "product_name": recommendation['name'],
            "score": recommendation['final_score'],
            "reason": f"Cross-Encoder ì ìˆ˜: {recommendation['ce_score']:.4f}, í‚¤ì›Œë“œ ë§¤ì¹­: {recommendation['kw_bonus']:.3f}",
            "product_data": {
                "product_id": recommendation['product_id'],
                "brand": recommendation['brand'],
                "name": recommendation['name'],
                "category": {
                    "major": recommendation['category_major'],
                    "middle": recommendation['category_middle'],
                    "small": recommendation['category_small'],
                },
                "price": {
                    "original_price": recommendation['price_final'],
                    "discounted_price": recommendation['price_final'],
                    "discount_rate": recommendation['discount_rate'],
                },
                "review": {
                    "score": recommendation['review_score'],
                    "count": recommendation['review_count'],
                    "top_keywords": [],
                },
                "description_short": f"{recommendation['name']} - {recommendation['brand']}",
            }
        }
        return result
    
    # ì¶”ì²œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    print("  âš ï¸ ì¶”ì²œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜")
    return {
        "product_id": "UNKNOWN",
        "product_name": "ì¶”ì²œ ì‹¤íŒ¨",
        "score": 0.0,
        "reason": "ìƒí’ˆ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
    }


